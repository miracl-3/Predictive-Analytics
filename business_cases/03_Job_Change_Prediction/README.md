# Decision Tree and Random Forest Classification

This project demonstrates the application of **tree-based machine learning models** to solve a supervised classification problem using structured data. The notebook covers the full analytical workflow from data preparation to model evaluation and comparison.

## Objective

To build and compare Decision Tree and Random Forest classifiers in order to predict business outcomes and identify key factors influencing those predictions.

## Workflow

The notebook follows a structured machine learning pipeline:

* Exploratory Data Analysis (EDA) to understand feature distributions and target behavior
* Data cleaning and preprocessing, including handling missing values and encoding categorical variables
* Feature preparation for tree-based models
* Training a Decision Tree classifier as a baseline model
* Training a Random Forest classifier to improve predictive performance
* Comparing model results using standard evaluation metrics

## Models Used

* Decision Tree Classifier
* Random Forest Classifier

Decision Trees provide interpretability and insight into decision rules, while Random Forest improves robustness and accuracy through ensemble learning.

## Evaluation Metrics

* Accuracy
* Precision
* Recall
* F1-score

These metrics are used to evaluate model effectiveness and alignment with business objectives.

## Tools & Technologies

* Python
* pandas, NumPy
* scikit-learn
* matplotlib, seaborn
* Jupyter Notebook

## Outcome

The project highlights the strengths and trade-offs between single-tree and ensemble-based models, demonstrating how Random Forest can enhance predictive performance while maintaining meaningful feature insights.

## Files

* `Decision_Tree_Random_Forest_Classifier.ipynb` â€“ Jupyter notebook containing data preprocessing, model training, and evaluation
